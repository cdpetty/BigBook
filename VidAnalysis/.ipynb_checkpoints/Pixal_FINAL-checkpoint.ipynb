{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixal: The Music Video Classifier\n",
    "**CSCE 489: Data Science and Analytics - Spring Fall 2016**  \n",
    "Christopher Foy, Clayton Petty, Dalton Harris, Wesley Moncrief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Motivation\n",
    "\n",
    "Have you ever been watching a music video and stop and ask yourself: \"Man, I wish I knew which genre this song is.\" Just weeks ago, this was us. Four college students with no sense of harmonic direction, just trying to find some musical fusion in our lives. We set out to find solution to this problem, and build a tool that analyzes music videos from YouTube and classifies them by genre. \n",
    "\n",
    "We wanted to find out if it was possible to intelligently determine the genre of a video by its youtube metadata (likes, dislikes, view count, etc.) and its average frame colors throughout the video.  \n",
    "\n",
    "After thorough analysis, Pixal emerged: a web interface that takes a YouTube URL as input, and outputs a predicted genre. This is done using a combination of OpenCV color analysis and scikit-learn machine learning, and makes intelligent assumptions on our data to output a substantially accurate genre classification for the input video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Work\n",
    "\n",
    "Our motivation primarily comes from GitHub user [Sacert's 'Colors of Film' analysis](https://github.com/sacert/Colors-of-Film), in which he analyzed popular Hollywood films and extracted avereage frame colors. He used OpenCV and some built-in python libraries to generate his output, which is an image with colors from each frame of the movie. Below is the output image for *Harry Potter and the Prizoner of Azkaban:*\n",
    "![Harry Potter and the Prizoner of Azkaban Average Color Image](https://raw.githubusercontent.com/sacert/Colors-of-Film/master/output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Questions\n",
    "\n",
    "When we began our analysis, the question we asked was, *\"Can we accurately predict music genre by analyzing various aspects of a music video\"*.  This question was obviously extremely broad, and we quickly realized that we needed to narrow the scope and focus in on a few **important/relevant** features.\n",
    "\n",
    "Thus, we revised our question to, *\"Can we accurately predict music genre by analyzing average frame color and youtube's video metadata (likes, dislikes, viewcount, etc.)\"*.  This question was much more manageable, but was more geared towards a final product than the actual data science process.\n",
    "\n",
    "We then divided our project into two separate questions, with connected, but different goals. Firstly, *\"What are the most defining/relevant features for a music video when it comes to genre\"*, and, *\"Is it possible to leverage these features to accurately predict the genre of a music video\"*.  These are the two questions that our project really sought to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aquisition and Cleaning\n",
    "\n",
    "We employed several techniques to gather and aggregate the data we needed.\n",
    "\n",
    "**Date Acquisition**  \n",
    "Firstly, we chose five of the most common genres to focus on and found a YouTube playlist for each of them. We used a chrome extension called [scraper](https://chrome.google.com/webstore/detail/scraper/mbigbapnjcgaffohmbkdlecaccepngjd?hl=en) to download the links to the top 200 videos in each playlist. Then, we used [Pafy](https://pythonhosted.org/Pafy/), a python library, to download each of the videos. Pafy also allowed us to access the metadata (view count, rating, etc.) that we needed.\n",
    "\n",
    "**Compressing Videos**  \n",
    "In order to speed up our frame-by-frame analysis of the videos, we wrote a [script](https://github.com/cdpetty/Pixal/blob/master/Videos2/condense_vids.py) using 'ffmpeg', a video conversion tool, to lower the quality of videos, and therefore decrease the number of frames to analyze. \n",
    "\n",
    "**Analyzing Frame Colors**  \n",
    "With skvideo, we iterated over the frames of each video. Originally, we took the average color of all the pixels in the frames. However, we quickly found that almost every frame's color averaged out to gray. Because of this, we decided to look at the most commonly appearing (mode) color of each frame. We then took the 10 most common frame colors throughout the video. These became the RGB values that we used in our analysis.\n",
    "\n",
    "#### Here is the data that we started with, after pulling down Youtube metadata and running our [color analysis script](https://github.com/cdpetty/Pixal/blob/master/VidAnalysis/analyzer.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>rating</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>duration</th>\n",
       "      <th>length</th>\n",
       "      <th>keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>colors_8_red</th>\n",
       "      <th>colors_8_blue</th>\n",
       "      <th>colors_8_green</th>\n",
       "      <th>colors_9_red</th>\n",
       "      <th>colors_9_blue</th>\n",
       "      <th>colors_9_green</th>\n",
       "      <th>colors_10_red</th>\n",
       "      <th>colors_10_blue</th>\n",
       "      <th>colors_10_green</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luke Bryan - Roller Coaster.mp4</td>\n",
       "      <td>LukeBryanVEVO</td>\n",
       "      <td>Luke Bryan - Crash My Party\\nPurchase now on i...</td>\n",
       "      <td>28948653</td>\n",
       "      <td>4.840108</td>\n",
       "      <td>127866</td>\n",
       "      <td>5324</td>\n",
       "      <td>00:04:23</td>\n",
       "      <td>263</td>\n",
       "      <td>[Luke, Bryan, Roller, Coaster, Capitol, Record...</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>210</td>\n",
       "      <td>190</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>240</td>\n",
       "      <td>220</td>\n",
       "      <td>200</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dierks Bentley - Drunk On A Plane.mp4</td>\n",
       "      <td>DierksBentleyVEVO</td>\n",
       "      <td>Purchase Dierks Bentley’s latest music: http:/...</td>\n",
       "      <td>41548786</td>\n",
       "      <td>4.763639</td>\n",
       "      <td>140682</td>\n",
       "      <td>8835</td>\n",
       "      <td>00:04:51</td>\n",
       "      <td>291</td>\n",
       "      <td>[Dierks, Bentley, Drunk, On, Plane, Capitol, R...</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas Rhett - Get Me Some Of That.mp4</td>\n",
       "      <td>ThomasRhettVEVO</td>\n",
       "      <td>Music video by Thomas Rhett performing Get Me ...</td>\n",
       "      <td>43868160</td>\n",
       "      <td>4.826069</td>\n",
       "      <td>128488</td>\n",
       "      <td>5841</td>\n",
       "      <td>00:03:13</td>\n",
       "      <td>193</td>\n",
       "      <td>[Thomas, Rhett, Get, Me, Some, Of, That, The, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename             author  \\\n",
       "0         Luke Bryan - Roller Coaster.mp4      LukeBryanVEVO   \n",
       "1   Dierks Bentley - Drunk On A Plane.mp4  DierksBentleyVEVO   \n",
       "2  Thomas Rhett - Get Me Some Of That.mp4    ThomasRhettVEVO   \n",
       "\n",
       "                                         description  viewcount    rating  \\\n",
       "0  Luke Bryan - Crash My Party\\nPurchase now on i...   28948653  4.840108   \n",
       "1  Purchase Dierks Bentley’s latest music: http:/...   41548786  4.763639   \n",
       "2  Music video by Thomas Rhett performing Get Me ...   43868160  4.826069   \n",
       "\n",
       "    likes  dislikes  duration  length  \\\n",
       "0  127866      5324  00:04:23     263   \n",
       "1  140682      8835  00:04:51     291   \n",
       "2  128488      5841  00:03:13     193   \n",
       "\n",
       "                                            keywords   ...    colors_8_red  \\\n",
       "0  [Luke, Bryan, Roller, Coaster, Capitol, Record...   ...             230   \n",
       "1  [Dierks, Bentley, Drunk, On, Plane, Capitol, R...   ...              70   \n",
       "2  [Thomas, Rhett, Get, Me, Some, Of, That, The, ...   ...              40   \n",
       "\n",
       "   colors_8_blue  colors_8_green  colors_9_red  colors_9_blue  colors_9_green  \\\n",
       "0            210             190            90             70              70   \n",
       "1             50              50           100            110             120   \n",
       "2             50              30            50             70              50   \n",
       "\n",
       "   colors_10_red  colors_10_blue  colors_10_green    genre  \n",
       "0            240             220              200  country  \n",
       "1             90              70               70  country  \n",
       "2             40              60               50  country  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import sklearn\n",
    "\n",
    "# Edit path if need be (shouldn't need to b/c we all have the same folder structure)\n",
    "CSV_PATH_1 = '../Videos/all_data'\n",
    "CSV_PATH_2 = '../Videos2/all_data2'\n",
    "FILE_EXTENSION = '_all.csv'\n",
    "GENRES = ['country', 'edm', 'pop', 'rap', 'rock']\n",
    "\n",
    "# Containers for the data frames\n",
    "genre_dfs = {}\n",
    "all_genres = None\n",
    "\n",
    "# Read in the 5 genre's of CV's\n",
    "for genre in GENRES:\n",
    "    genre_csv_path_1 = path.join(CSV_PATH_1, genre) + FILE_EXTENSION\n",
    "    genre_csv_path_2 = path.join(CSV_PATH_2, genre) + FILE_EXTENSION\n",
    "    df_1 = pd.read_csv(genre_csv_path_1)\n",
    "    df_2 = pd.read_csv(genre_csv_path_2)\n",
    "    df_1 = df_1.drop('Unnamed: 0',1)\n",
    "    df_2 = df_2.drop('Unnamed: 0',1)\n",
    "    df_combined = pd.concat([df_1,df_2],ignore_index=True)\n",
    "    genre_dfs[genre] = df_combined\n",
    "\n",
    "all_genres = pd.concat(genre_dfs.values())\n",
    "all_genres.head(3)\n",
    "\n",
    "# genre_dfs is now a dictionary that contains the 5 different data frames\n",
    "# all_genres is a dataframe that contains all of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we formated the data for our analysis:\n",
    "\n",
    "In accordance with scikit-learn, we had to make the genres ordinal to fit in the random forest classifiers. We add a new column to our dataframe to do so, write a function to populate it, and run it across the dataframe. We also create binary genre columns for each genre for additional analysis.\n",
    "\n",
    "We create our training and test sets by splitting all_genres by genre, and making ~100 of each genre train and ~100 test. We aggregate by genre to make our full train and full test sets, each containing ~500 records of various genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Records:\t405\n",
      "Test Records:\t\t405\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>rating</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>duration</th>\n",
       "      <th>length</th>\n",
       "      <th>keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>colors_10_red</th>\n",
       "      <th>colors_10_blue</th>\n",
       "      <th>colors_10_green</th>\n",
       "      <th>genre</th>\n",
       "      <th>genre_ordinal</th>\n",
       "      <th>is_country</th>\n",
       "      <th>is_rock</th>\n",
       "      <th>is_edm</th>\n",
       "      <th>is_rap</th>\n",
       "      <th>is_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luke Bryan - Roller Coaster.mp4</td>\n",
       "      <td>LukeBryanVEVO</td>\n",
       "      <td>Luke Bryan - Crash My Party\\nPurchase now on i...</td>\n",
       "      <td>28948653</td>\n",
       "      <td>4.840108</td>\n",
       "      <td>127866</td>\n",
       "      <td>5324</td>\n",
       "      <td>00:04:23</td>\n",
       "      <td>263</td>\n",
       "      <td>[Luke, Bryan, Roller, Coaster, Capitol, Record...</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>220</td>\n",
       "      <td>200</td>\n",
       "      <td>country</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dierks Bentley - Drunk On A Plane.mp4</td>\n",
       "      <td>DierksBentleyVEVO</td>\n",
       "      <td>Purchase Dierks Bentley’s latest music: http:/...</td>\n",
       "      <td>41548786</td>\n",
       "      <td>4.763639</td>\n",
       "      <td>140682</td>\n",
       "      <td>8835</td>\n",
       "      <td>00:04:51</td>\n",
       "      <td>291</td>\n",
       "      <td>[Dierks, Bentley, Drunk, On, Plane, Capitol, R...</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>country</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas Rhett - Get Me Some Of That.mp4</td>\n",
       "      <td>ThomasRhettVEVO</td>\n",
       "      <td>Music video by Thomas Rhett performing Get Me ...</td>\n",
       "      <td>43868160</td>\n",
       "      <td>4.826069</td>\n",
       "      <td>128488</td>\n",
       "      <td>5841</td>\n",
       "      <td>00:03:13</td>\n",
       "      <td>193</td>\n",
       "      <td>[Thomas, Rhett, Get, Me, Some, Of, That, The, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>country</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Nail - Whatever She's Got.mp4</td>\n",
       "      <td>DavidNailVEVO</td>\n",
       "      <td>Purchase David Nail’s latest music: http://umg...</td>\n",
       "      <td>48648247</td>\n",
       "      <td>4.826632</td>\n",
       "      <td>141108</td>\n",
       "      <td>6393</td>\n",
       "      <td>00:04:01</td>\n",
       "      <td>241</td>\n",
       "      <td>[David, Nail, Whatever, She's, Got, MCA, Nashv...</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>country</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joe Nichols - Yeah.mp4</td>\n",
       "      <td>JoeNicholsVEVO</td>\n",
       "      <td>Joe Nichols - Yeah\\n“Yeah” from Joe Nichol’s C...</td>\n",
       "      <td>11397694</td>\n",
       "      <td>4.815725</td>\n",
       "      <td>33255</td>\n",
       "      <td>1606</td>\n",
       "      <td>00:03:52</td>\n",
       "      <td>232</td>\n",
       "      <td>[Joe Nichols, Red Bow Records, Country, Yeah]</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>country</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename             author  \\\n",
       "0         Luke Bryan - Roller Coaster.mp4      LukeBryanVEVO   \n",
       "1   Dierks Bentley - Drunk On A Plane.mp4  DierksBentleyVEVO   \n",
       "2  Thomas Rhett - Get Me Some Of That.mp4    ThomasRhettVEVO   \n",
       "3     David Nail - Whatever She's Got.mp4      DavidNailVEVO   \n",
       "4                  Joe Nichols - Yeah.mp4     JoeNicholsVEVO   \n",
       "\n",
       "                                         description  viewcount    rating  \\\n",
       "0  Luke Bryan - Crash My Party\\nPurchase now on i...   28948653  4.840108   \n",
       "1  Purchase Dierks Bentley’s latest music: http:/...   41548786  4.763639   \n",
       "2  Music video by Thomas Rhett performing Get Me ...   43868160  4.826069   \n",
       "3  Purchase David Nail’s latest music: http://umg...   48648247  4.826632   \n",
       "4  Joe Nichols - Yeah\\n“Yeah” from Joe Nichol’s C...   11397694  4.815725   \n",
       "\n",
       "    likes  dislikes  duration  length  \\\n",
       "0  127866      5324  00:04:23     263   \n",
       "1  140682      8835  00:04:51     291   \n",
       "2  128488      5841  00:03:13     193   \n",
       "3  141108      6393  00:04:01     241   \n",
       "4   33255      1606  00:03:52     232   \n",
       "\n",
       "                                            keywords   ...   colors_10_red  \\\n",
       "0  [Luke, Bryan, Roller, Coaster, Capitol, Record...   ...             240   \n",
       "1  [Dierks, Bentley, Drunk, On, Plane, Capitol, R...   ...              90   \n",
       "2  [Thomas, Rhett, Get, Me, Some, Of, That, The, ...   ...              40   \n",
       "3  [David, Nail, Whatever, She's, Got, MCA, Nashv...   ...              70   \n",
       "4      [Joe Nichols, Red Bow Records, Country, Yeah]   ...              20   \n",
       "\n",
       "   colors_10_blue  colors_10_green    genre  genre_ordinal  is_country  \\\n",
       "0             220              200  country              0           1   \n",
       "1              70               70  country              0           1   \n",
       "2              60               50  country              0           1   \n",
       "3              60               50  country              0           1   \n",
       "4              30               50  country              0           1   \n",
       "\n",
       "   is_rock  is_edm  is_rap  is_pop  \n",
       "0        0       0       0       0  \n",
       "1        0       0       0       0  \n",
       "2        0       0       0       0  \n",
       "3        0       0       0       0  \n",
       "4        0       0       0       0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def genre_to_ordinal(genre_in):\n",
    "    if(genre_in == \"country\"):\n",
    "        return 0\n",
    "    elif(genre_in == \"pop\"):\n",
    "        return 1\n",
    "    elif(genre_in == \"rock\"):\n",
    "        return 2\n",
    "    elif(genre_in == \"edm\"):\n",
    "        return 3\n",
    "    elif(genre_in == \"rap\"):\n",
    "        return 4\n",
    "    else:\n",
    "        return genre_in\n",
    "    \n",
    "all_genres['genre_ordinal'] = all_genres.genre.apply(genre_to_ordinal)\n",
    "\n",
    "# Adding is_country flag\n",
    "def is_country(genre_in):\n",
    "    if(genre_in == \"country\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_country'] = all_genres.genre.apply(is_country)\n",
    "\n",
    "# Adding is_country flag\n",
    "def is_rock(genre_in):\n",
    "    if(genre_in == \"rock\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_rock'] = all_genres.genre.apply(is_rock)\n",
    "\n",
    "# Adding is_edm flag\n",
    "def is_edm(genre_in):\n",
    "    if(genre_in == \"edm\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_edm'] = all_genres.genre.apply(is_edm)\n",
    "\n",
    "# Adding is_rap flag\n",
    "def is_rap(genre_in):\n",
    "    if(genre_in == \"rap\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_rap'] = all_genres.genre.apply(is_rap)\n",
    "\n",
    "# Adding is_country flag\n",
    "def is_pop(genre_in):\n",
    "    if(genre_in == \"pop\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_pop'] = all_genres.genre.apply(is_pop)\n",
    "\n",
    "# Subset all_genres to group by individual genres\n",
    "country_records  = all_genres[all_genres[\"genre\"] == \"country\"]\n",
    "rock_records     = all_genres[all_genres[\"genre\"] == \"rock\"]\n",
    "pop_records      = all_genres[all_genres[\"genre\"] == \"pop\"]\n",
    "edm_records      = all_genres[all_genres[\"genre\"] == \"edm\"]\n",
    "rap_records      = all_genres[all_genres[\"genre\"] == \"rap\"]\n",
    "\n",
    "# From the subsets above, create train and test sets from each\n",
    "country_train = country_records.head(len(country_records) / 2)\n",
    "country_test  = country_records.tail(len(country_records) / 2)\n",
    "rock_train    = rock_records.head(len(rock_records) / 2)\n",
    "rock_test     = rock_records.tail(len(rock_records) / 2)\n",
    "pop_train     = pop_records.head(len(pop_records) / 2)\n",
    "pop_test      = pop_records.tail(len(pop_records) / 2)\n",
    "edm_train     = edm_records.head(len(edm_records) / 2)\n",
    "edm_test      = edm_records.tail(len(edm_records) / 2)\n",
    "rap_train     = rap_records.head(len(rap_records) / 2)\n",
    "rap_test      = rap_records.tail(len(rap_records) / 2)\n",
    "\n",
    "# Create big training and big test set for analysis\n",
    "training_set = pd.concat([country_train,rock_train,pop_train,edm_train,rap_train])\n",
    "test_set     = pd.concat([country_test,rock_test,pop_test,edm_test,rap_test])\n",
    "\n",
    "training_set = training_set.fillna(0)\n",
    "test_set = test_set.fillna(0)\n",
    "\n",
    "print \"Training Records:\\t\" , len(training_set)\n",
    "print \"Test Records:\\t\\t\" , len(test_set)\n",
    "\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above **training_set** and **test_set** were the two dataframes that we use for analysis over the course of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "What follows is our initial gathering and analysis of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Generating Random Forest - Viewer Statistics\n",
    "We start generating our random forests, and output a relative accuracy and a confusion matrix. In this first one, we simply factor in non-color variables (rating, likes, dislikes, length and viewcount), and run it across all records to predict an ordinal genre value.\n",
    "\n",
    "As you will see, this method yields relatively poor results. This is because there's no distinct clusters being created by our random forest, and simple viewer statistics tell us nothing about what kind of video we're watching. However, we see that country, rap and pop are initially somewhat distinct (diagonal is the highest value), and rock and edm are getting mistaken for one another. Let's see if we can't make something of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.412345679012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4\n",
       "Actual                       \n",
       "0          45   4   1  23   8\n",
       "1           0  26  36  11   8\n",
       "2          26  12   3  30   4\n",
       "3           4  21  22  24  12\n",
       "4           7  20   2   6  50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting based solely on non-color features, using RF\n",
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "meta_data_features = ['rating', 'likes','dislikes','length','viewcount']\n",
    "y, _ = pd.factorize(training_set['genre_ordinal'])\n",
    "clf = clf.fit(training_set[meta_data_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['genre_ordinal'])\n",
    "print clf.score(test_set[meta_data_features],z)\n",
    "pd.crosstab(test_set.genre_ordinal, clf.predict(test_set[meta_data_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Only Color Statistics\n",
    "Below, we do the same random forest as above, but strictly off of average frame color for the video.\n",
    "\n",
    "As shown below, this actually yields worse results than just the viewer statistics, because the color of a video by itself does not determine the genre. If rappers only had red in their videos and rockers only had black this might be somewhat accurate, but that's just not the case. But, what if we pair these findings with our initial viewer statistics? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22962962963\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4\n",
       "Actual                       \n",
       "0          25  29  10  13   4\n",
       "1          15  11  23  15  17\n",
       "2          27  23   9   8   8\n",
       "3          19  16  28   9  11\n",
       "4          20  14  23  15  13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_new_headers(old_headers):\n",
    "    headers = ['colors_' + str(x+1) + '_' for x in range(10)]\n",
    "    h = []\n",
    "    for x in headers:\n",
    "        h.append(x + 'red')\n",
    "        h.append(x + 'blue')\n",
    "        h.append(x + 'green')\n",
    "    return old_headers + h + ['genre']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "color_features = gen_new_headers([])[:-1]\n",
    "\n",
    "# Predicting based solely on colors\n",
    "y, _ = pd.factorize(training_set['genre_ordinal'])\n",
    "clf = clf.fit(training_set[color_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['genre_ordinal'])\n",
    "print clf.score(test_set[color_features],z)\n",
    "pd.crosstab(test_set.genre_ordinal, clf.predict(test_set[color_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - All Features  \n",
    "\n",
    "Here we use all metadata and color data gathered. This approach, unsurprisingly, yields a success rate somewhere in between the solely-color and solely-metadata classification success rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36049382716\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4\n",
       "Actual                       \n",
       "0          38   7   1  18  17\n",
       "1          11  14  35  12   9\n",
       "2          28  18   2  16  11\n",
       "3          14  11  21  26  11\n",
       "4          26  11   5  14  29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "all_features = meta_data_features + color_features\n",
    "\n",
    "# Predicting based on colors and non-color features\n",
    "y, _ = pd.factorize(training_set['genre_ordinal'])\n",
    "clf = clf.fit(training_set[all_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['genre_ordinal'])\n",
    "print clf.score(test_set[all_features],z)\n",
    "pd.crosstab(test_set.genre_ordinal, clf.predict(test_set[all_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classifiers\n",
    "Scores were low, morale was down. It seems as if we're trying to make the classifier do way too much work by forcing it to choose from 5 different possible genres. The next step, then, was to use the binary features that we created initially.\n",
    "\n",
    "First, we try Pop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81975308642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1\n",
       "Actual            \n",
       "0          307  17\n",
       "1           56  25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "all_features = meta_data_features + color_features\n",
    "\n",
    "# Predicting based on colors and non-color features\n",
    "y, _ = pd.factorize(training_set['is_pop'])\n",
    "clf = clf.fit(training_set[all_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['is_pop'])\n",
    "print clf.score(test_set[all_features],z)\n",
    "pd.crosstab(test_set.is_pop, clf.predict(test_set[all_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753086419753\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1\n",
       "Actual            \n",
       "0          285  35\n",
       "1           65  20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "all_features = meta_data_features + color_features\n",
    "\n",
    "# Predicting based on colors and non-color features\n",
    "y, _ = pd.factorize(training_set['is_rap'])\n",
    "clf = clf.fit(training_set[all_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['is_rap'])\n",
    "print clf.score(test_set[all_features],z)\n",
    "pd.crosstab(test_set.is_rap, clf.predict(test_set[all_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're seeing above is a confusion matrix that, based on our training data, predicts whether or not a video in the test set is a pop video or not. You can see that it predicted 299 + 25 = 324 videos correctly, versus 60 + 21 = 81 videos incorrectly.\n",
    "\n",
    "The confusion matrix above is our first effort at utilizing these binary classifiers. The classifier does a relatively good job with a success rate of 80%. However, we could use some improvement in the realm of \"false negatives\", where the model classified a video as not pop when it actually was.\n",
    "\n",
    "We attempt this same test for each genre, and run the test multiple times to see what our average success rate is for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for 20 is_pop iterations: 0.815308641975\n",
      "Average Score for 20 is_rap iterations: 0.77987654321\n",
      "Average Score for 20 is_rock iterations: 0.817777777778\n",
      "Average Score for 20 is_edm iterations: 0.762345679012\n",
      "Average Score for 20 is_country iterations: 0.793333333333\n"
     ]
    }
   ],
   "source": [
    "training_set = pd.concat([country_train,rock_train,pop_train,edm_train,rap_train])\n",
    "test_set     = pd.concat([country_test,rock_test,pop_test,edm_test,rap_test])\n",
    "\n",
    "def multi_RF_averages(is_genre,num_iterations):\n",
    "    clf = RandomForestClassifier(n_estimators=11)\n",
    "    loop_indices = range(0,num_iterations)\n",
    "    cumsum = 0\n",
    "\n",
    "    for i in loop_indices:\n",
    "        y, _ = pd.factorize(training_set[is_genre])\n",
    "        clf = clf.fit(training_set[all_features], y)\n",
    "\n",
    "        z, _ = pd.factorize(test_set[is_genre])\n",
    "        cumsum = cumsum + clf.score(test_set[all_features],z)\n",
    "    \n",
    "    \n",
    "    print \"Average Score for\",len(loop_indices),is_genre,\"iterations:\", cumsum/len(loop_indices)\n",
    "\n",
    "NUM_TIMES = 20\n",
    "pop_class = multi_RF_averages(\"is_pop\", NUM_TIMES)\n",
    "rap_class = multi_RF_averages(\"is_rap\", NUM_TIMES)\n",
    "rock_class = multi_RF_averages(\"is_rock\", NUM_TIMES)\n",
    "edm_class = multi_RF_averages(\"is_edm\", NUM_TIMES)\n",
    "country_class = multi_RF_averages(\"is_country\", NUM_TIMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at certain genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for 50 is_country iterations: 0.85987654321\n",
      "Average Score for 50 is_pop iterations: 0.860617283951\n",
      "--------------------------------\n",
      "Average Score for 50 is_rock iterations: 0.587974683544\n",
      "Average Score for 50 is_edm iterations: 0.585696202532\n"
     ]
    }
   ],
   "source": [
    "# Removing EDM for better analysis - makes is_pop and is_rap much more accurate\n",
    "# training_set = pd.concat([rock_train,edm_train,country_train,pop_train])\n",
    "# test_set     = pd.concat([rock_test,edm_test,country_test,pop_test])\n",
    "\n",
    "training_set = pd.concat([country_train,pop_train])\n",
    "test_set     = pd.concat([country_test,pop_test])\n",
    "multi_RF_averages(\"is_country\",50)\n",
    "multi_RF_averages(\"is_pop\",50)\n",
    "\n",
    "print '--------------------------------'\n",
    "\n",
    "training_set = pd.concat([edm_train,rock_train])\n",
    "test_set     = pd.concat([edm_test,rock_test])\n",
    "multi_RF_averages(\"is_rock\",50)\n",
    "multi_RF_averages(\"is_edm\",50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So, what does this tell us? It seems that country and pop are easy to distinguish between while rock and edm are significantly harder to differentiate. \n",
    "\n",
    "Next let's look at which genres seem to be the best at identifying themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for 50 is_rock iterations: 0.8144\n",
      "Average Score for 50 is_rap iterations: 0.736705882353\n",
      "Average Score for 50 is_country iterations: 0.214320987654\n",
      "Average Score for 50 is_pop iterations: 0.731851851852\n",
      "Average Score for 50 is_edm iterations: 0.924819277108\n"
     ]
    }
   ],
   "source": [
    "training_set = pd.concat([country_train,rock_train,edm_train,rap_train,pop_train])\n",
    "\n",
    "test_set     = pd.concat([rock_test])\n",
    "multi_RF_averages(\"is_rock\",50)\n",
    "\n",
    "test_set     = pd.concat([rap_test])\n",
    "multi_RF_averages(\"is_rap\",50)\n",
    "\n",
    "test_set     = pd.concat([country_test])\n",
    "multi_RF_averages(\"is_country\",50)\n",
    "\n",
    "test_set     = pd.concat([pop_test])\n",
    "multi_RF_averages(\"is_pop\",50)\n",
    "\n",
    "test_set     = pd.concat([edm_test])\n",
    "multi_RF_averages(\"is_edm\",50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something seems to be going on with Country. Let's also take a look at EDM which seems to be very successful at differentiating itself from other genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>288</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1\n",
       "Actual            \n",
       "0          288  34\n",
       "1           74   9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.concat([country_train,rock_train,pop_train,edm_train,rap_train])\n",
    "test_set     = pd.concat([country_test,rock_test,pop_test,edm_test,rap_test])\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "all_features = meta_data_features + color_features\n",
    "y, _ = pd.factorize(training_set['is_edm'])\n",
    "clf = clf.fit(training_set[all_features], y)\n",
    "z, _ = pd.factorize(test_set['is_edm'])\n",
    "pd.crosstab(test_set.is_edm, clf.predict(test_set[all_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1\n",
       "Actual            \n",
       "0          21  303\n",
       "1          25   56"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.concat([country_train,rock_train,pop_train,edm_train,rap_train])\n",
    "test_set     = pd.concat([country_test,rock_test,pop_test,edm_test,rap_test])\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "all_features = meta_data_features + color_features\n",
    "y, _ = pd.factorize(training_set['is_country'])\n",
    "clf = clf.fit(training_set[all_features], y)\n",
    "z, _ = pd.factorize(test_set['is_country'])\n",
    "pd.crosstab(test_set.is_country, clf.predict(test_set[all_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see some interesting insights. It seems that when it comes to classifying for country, everything looks like country. You'll notice that the country classifier incorrectly labels a large number (~300) non-country videos as country. This is opposed to the EDM classifier which does not suffer from these issues.\n",
    "\n",
    "Where EDM suffers, is that it has a hard time correctly identifying itself as EDM.  \n",
    "\n",
    "Essentially, this means that neither EDM or Country are very distinguishable. No videos seem to look like EDM videos (including EDM videos themselves), while every video seems to look like a country video.\n",
    "\n",
    "Now let's look at which feature seems to be the most helpful in classifying videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Most Valuable Features per Genre - Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "\n",
    "training_set = pd.concat([country_train,pop_train,rap_train,rock_train,edm_train])\n",
    "y, _ = pd.factorize(training_set['is_rock'])\n",
    "model.fit(training_set[all_features], y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rap</th>\n",
       "      <th>rock</th>\n",
       "      <th>country</th>\n",
       "      <th>edm</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rating</td>\n",
       "      <td>0.030114</td>\n",
       "      <td>0.048283</td>\n",
       "      <td>0.049655</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.031334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>likes</td>\n",
       "      <td>0.049235</td>\n",
       "      <td>0.032803</td>\n",
       "      <td>0.051736</td>\n",
       "      <td>0.031412</td>\n",
       "      <td>0.173424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dislikes</td>\n",
       "      <td>0.035565</td>\n",
       "      <td>0.025664</td>\n",
       "      <td>0.038277</td>\n",
       "      <td>0.032610</td>\n",
       "      <td>0.117250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>length</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>0.050534</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.015547</td>\n",
       "      <td>0.017044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>viewcount</td>\n",
       "      <td>0.066519</td>\n",
       "      <td>0.025964</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.035622</td>\n",
       "      <td>0.157179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>colors_1_red</td>\n",
       "      <td>0.034143</td>\n",
       "      <td>0.029190</td>\n",
       "      <td>0.025543</td>\n",
       "      <td>0.028371</td>\n",
       "      <td>0.019291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>colors_1_blue</td>\n",
       "      <td>0.029758</td>\n",
       "      <td>0.042955</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>0.024189</td>\n",
       "      <td>0.010326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>colors_1_green</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>0.026605</td>\n",
       "      <td>0.019925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>colors_2_red</td>\n",
       "      <td>0.018012</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>0.026022</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.011589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>colors_2_blue</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.025164</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>0.021275</td>\n",
       "      <td>0.012560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>colors_2_green</td>\n",
       "      <td>0.035542</td>\n",
       "      <td>0.038929</td>\n",
       "      <td>0.023882</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>0.012886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>colors_3_red</td>\n",
       "      <td>0.021575</td>\n",
       "      <td>0.026393</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>0.023349</td>\n",
       "      <td>0.019746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>colors_3_blue</td>\n",
       "      <td>0.019488</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.033688</td>\n",
       "      <td>0.020881</td>\n",
       "      <td>0.015841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>colors_3_green</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>0.035658</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>0.019905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>colors_4_red</td>\n",
       "      <td>0.029622</td>\n",
       "      <td>0.027755</td>\n",
       "      <td>0.042786</td>\n",
       "      <td>0.029943</td>\n",
       "      <td>0.022475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>colors_4_blue</td>\n",
       "      <td>0.029286</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.029601</td>\n",
       "      <td>0.032764</td>\n",
       "      <td>0.021904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>colors_4_green</td>\n",
       "      <td>0.029729</td>\n",
       "      <td>0.033211</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>0.026235</td>\n",
       "      <td>0.012917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colors_5_red</td>\n",
       "      <td>0.027483</td>\n",
       "      <td>0.033806</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.032858</td>\n",
       "      <td>0.030169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>colors_5_blue</td>\n",
       "      <td>0.021061</td>\n",
       "      <td>0.027489</td>\n",
       "      <td>0.026155</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.012220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>colors_5_green</td>\n",
       "      <td>0.021108</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>0.020451</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>0.015867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>colors_6_red</td>\n",
       "      <td>0.027929</td>\n",
       "      <td>0.031957</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>0.030660</td>\n",
       "      <td>0.014532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>colors_6_blue</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>0.033222</td>\n",
       "      <td>0.030829</td>\n",
       "      <td>0.017398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>colors_6_green</td>\n",
       "      <td>0.022319</td>\n",
       "      <td>0.029538</td>\n",
       "      <td>0.038668</td>\n",
       "      <td>0.029713</td>\n",
       "      <td>0.012841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>colors_7_red</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.026425</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.027534</td>\n",
       "      <td>0.016651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>colors_7_blue</td>\n",
       "      <td>0.028094</td>\n",
       "      <td>0.022129</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>0.033678</td>\n",
       "      <td>0.020651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>colors_7_green</td>\n",
       "      <td>0.029397</td>\n",
       "      <td>0.019162</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.019418</td>\n",
       "      <td>0.017365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>colors_8_red</td>\n",
       "      <td>0.029581</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>0.021630</td>\n",
       "      <td>0.028143</td>\n",
       "      <td>0.014667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>colors_8_blue</td>\n",
       "      <td>0.028211</td>\n",
       "      <td>0.022028</td>\n",
       "      <td>0.026666</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.015064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>colors_8_green</td>\n",
       "      <td>0.026847</td>\n",
       "      <td>0.024699</td>\n",
       "      <td>0.038582</td>\n",
       "      <td>0.028111</td>\n",
       "      <td>0.011875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>colors_9_red</td>\n",
       "      <td>0.030285</td>\n",
       "      <td>0.027422</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.026830</td>\n",
       "      <td>0.009295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>colors_9_blue</td>\n",
       "      <td>0.032644</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>0.025195</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.019598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>colors_9_green</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.018673</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.024623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>colors_10_red</td>\n",
       "      <td>0.021648</td>\n",
       "      <td>0.028855</td>\n",
       "      <td>0.023344</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>0.016464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>colors_10_blue</td>\n",
       "      <td>0.026029</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>0.020642</td>\n",
       "      <td>0.038184</td>\n",
       "      <td>0.021881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>colors_10_green</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.026830</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>0.013240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index       rap      rock   country       edm       pop\n",
       "0            rating  0.030114  0.048283  0.049655  0.042053  0.031334\n",
       "1             likes  0.049235  0.032803  0.051736  0.031412  0.173424\n",
       "2          dislikes  0.035565  0.025664  0.038277  0.032610  0.117250\n",
       "3            length  0.025576  0.050534  0.022989  0.015547  0.017044\n",
       "4         viewcount  0.066519  0.025964  0.056759  0.035622  0.157179\n",
       "5      colors_1_red  0.034143  0.029190  0.025543  0.028371  0.019291\n",
       "6     colors_1_blue  0.029758  0.042955  0.017968  0.024189  0.010326\n",
       "7    colors_1_green  0.033149  0.032359  0.022861  0.026605  0.019925\n",
       "8      colors_2_red  0.018012  0.024338  0.026022  0.038835  0.011589\n",
       "9     colors_2_blue  0.015728  0.025164  0.011074  0.021275  0.012560\n",
       "10   colors_2_green  0.035542  0.038929  0.023882  0.020962  0.012886\n",
       "11     colors_3_red  0.021575  0.026393  0.019315  0.023349  0.019746\n",
       "12    colors_3_blue  0.019488  0.027848  0.033688  0.020881  0.015841\n",
       "13   colors_3_green  0.027751  0.035658  0.024506  0.025495  0.019905\n",
       "14     colors_4_red  0.029622  0.027755  0.042786  0.029943  0.022475\n",
       "15    colors_4_blue  0.029286  0.025898  0.029601  0.032764  0.021904\n",
       "16   colors_4_green  0.029729  0.033211  0.027292  0.026235  0.012917\n",
       "17     colors_5_red  0.027483  0.033806  0.019006  0.032858  0.030169\n",
       "18    colors_5_blue  0.021061  0.027489  0.026155  0.015619  0.012220\n",
       "19   colors_5_green  0.021108  0.019969  0.020451  0.037614  0.015867\n",
       "20     colors_6_red  0.027929  0.031957  0.030320  0.030660  0.014532\n",
       "21    colors_6_blue  0.019931  0.021496  0.033222  0.030829  0.017398\n",
       "22   colors_6_green  0.022319  0.029538  0.038668  0.029713  0.012841\n",
       "23     colors_7_red  0.030246  0.026425  0.031416  0.027534  0.016651\n",
       "24    colors_7_blue  0.028094  0.022129  0.023791  0.033678  0.020651\n",
       "25   colors_7_green  0.029397  0.019162  0.029013  0.019418  0.017365\n",
       "26     colors_8_red  0.029581  0.020734  0.021630  0.028143  0.014667\n",
       "27    colors_8_blue  0.028211  0.022028  0.026666  0.021853  0.015064\n",
       "28   colors_8_green  0.026847  0.024699  0.038582  0.028111  0.011875\n",
       "29     colors_9_red  0.030285  0.027422  0.021079  0.026830  0.009295\n",
       "30    colors_9_blue  0.032644  0.017291  0.025195  0.041853  0.019598\n",
       "31   colors_9_green  0.022461  0.018673  0.020036  0.031250  0.024623\n",
       "32    colors_10_red  0.021648  0.028855  0.023344  0.021040  0.016464\n",
       "33   colors_10_blue  0.026029  0.032120  0.020642  0.038184  0.021881\n",
       "34  colors_10_green  0.023933  0.023261  0.026830  0.028666  0.013240"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['index'] = all_features\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_rap'])\n",
    "model.fit(training_set[all_features], y)\n",
    "        \n",
    "df['rap'] = model.feature_importances_\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_rock'])\n",
    "model.fit(training_set[all_features], y)\n",
    "\n",
    "df['rock'] = model.feature_importances_\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_country'])\n",
    "model.fit(training_set[all_features], y)\n",
    "\n",
    "df['country'] = model.feature_importances_\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_edm'])\n",
    "model.fit(training_set[all_features], y)\n",
    "\n",
    "df['edm'] = model.feature_importances_\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_pop'])\n",
    "model.fit(training_set[all_features], y)\n",
    "\n",
    "df['pop'] = model.feature_importances_\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Improvements \n",
    "- Run the above graph a number of times, take the average for each cell\n",
    "- Based on the heaviest weighted parameters for each, run the random forest algorithm only taking these given parameters into consideration\n",
    "- Generate a model that classifies videos dynamically\n",
    "- Make more values ordinal - maybe to NLP or LDA to factor in descriptions, titles and lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [cs489]",
   "language": "python",
   "name": "Python [cs489]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
