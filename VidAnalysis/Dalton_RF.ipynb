{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>viewcount</th>\n",
       "      <th>rating</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>duration</th>\n",
       "      <th>length</th>\n",
       "      <th>keywords</th>\n",
       "      <th>...</th>\n",
       "      <th>colors_8_red</th>\n",
       "      <th>colors_8_blue</th>\n",
       "      <th>colors_8_green</th>\n",
       "      <th>colors_9_red</th>\n",
       "      <th>colors_9_blue</th>\n",
       "      <th>colors_9_green</th>\n",
       "      <th>colors_10_red</th>\n",
       "      <th>colors_10_blue</th>\n",
       "      <th>colors_10_green</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luke Bryan - Roller Coaster.mp4</td>\n",
       "      <td>LukeBryanVEVO</td>\n",
       "      <td>Luke Bryan - Crash My Party\\nPurchase now on i...</td>\n",
       "      <td>28948653</td>\n",
       "      <td>4.840108</td>\n",
       "      <td>127866</td>\n",
       "      <td>5324</td>\n",
       "      <td>00:04:23</td>\n",
       "      <td>263</td>\n",
       "      <td>[Luke, Bryan, Roller, Coaster, Capitol, Record...</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>210</td>\n",
       "      <td>190</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>240</td>\n",
       "      <td>220</td>\n",
       "      <td>200</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dierks Bentley - Drunk On A Plane.mp4</td>\n",
       "      <td>DierksBentleyVEVO</td>\n",
       "      <td>Purchase Dierks Bentley’s latest music: http:/...</td>\n",
       "      <td>41548786</td>\n",
       "      <td>4.763639</td>\n",
       "      <td>140682</td>\n",
       "      <td>8835</td>\n",
       "      <td>00:04:51</td>\n",
       "      <td>291</td>\n",
       "      <td>[Dierks, Bentley, Drunk, On, Plane, Capitol, R...</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas Rhett - Get Me Some Of That.mp4</td>\n",
       "      <td>ThomasRhettVEVO</td>\n",
       "      <td>Music video by Thomas Rhett performing Get Me ...</td>\n",
       "      <td>43868160</td>\n",
       "      <td>4.826069</td>\n",
       "      <td>128488</td>\n",
       "      <td>5841</td>\n",
       "      <td>00:03:13</td>\n",
       "      <td>193</td>\n",
       "      <td>[Thomas, Rhett, Get, Me, Some, Of, That, The, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Nail - Whatever She's Got.mp4</td>\n",
       "      <td>DavidNailVEVO</td>\n",
       "      <td>Purchase David Nail’s latest music: http://umg...</td>\n",
       "      <td>48648247</td>\n",
       "      <td>4.826632</td>\n",
       "      <td>141108</td>\n",
       "      <td>6393</td>\n",
       "      <td>00:04:01</td>\n",
       "      <td>241</td>\n",
       "      <td>[David, Nail, Whatever, She's, Got, MCA, Nashv...</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joe Nichols - Yeah.mp4</td>\n",
       "      <td>JoeNicholsVEVO</td>\n",
       "      <td>Joe Nichols - Yeah\\n“Yeah” from Joe Nichol’s C...</td>\n",
       "      <td>11397694</td>\n",
       "      <td>4.815725</td>\n",
       "      <td>33255</td>\n",
       "      <td>1606</td>\n",
       "      <td>00:03:52</td>\n",
       "      <td>232</td>\n",
       "      <td>[Joe Nichols, Red Bow Records, Country, Yeah]</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename             author  \\\n",
       "0         Luke Bryan - Roller Coaster.mp4      LukeBryanVEVO   \n",
       "1   Dierks Bentley - Drunk On A Plane.mp4  DierksBentleyVEVO   \n",
       "2  Thomas Rhett - Get Me Some Of That.mp4    ThomasRhettVEVO   \n",
       "3     David Nail - Whatever She's Got.mp4      DavidNailVEVO   \n",
       "4                  Joe Nichols - Yeah.mp4     JoeNicholsVEVO   \n",
       "\n",
       "                                         description  viewcount    rating  \\\n",
       "0  Luke Bryan - Crash My Party\\nPurchase now on i...   28948653  4.840108   \n",
       "1  Purchase Dierks Bentley’s latest music: http:/...   41548786  4.763639   \n",
       "2  Music video by Thomas Rhett performing Get Me ...   43868160  4.826069   \n",
       "3  Purchase David Nail’s latest music: http://umg...   48648247  4.826632   \n",
       "4  Joe Nichols - Yeah\\n“Yeah” from Joe Nichol’s C...   11397694  4.815725   \n",
       "\n",
       "    likes  dislikes  duration  length  \\\n",
       "0  127866      5324  00:04:23     263   \n",
       "1  140682      8835  00:04:51     291   \n",
       "2  128488      5841  00:03:13     193   \n",
       "3  141108      6393  00:04:01     241   \n",
       "4   33255      1606  00:03:52     232   \n",
       "\n",
       "                                            keywords   ...    colors_8_red  \\\n",
       "0  [Luke, Bryan, Roller, Coaster, Capitol, Record...   ...             230   \n",
       "1  [Dierks, Bentley, Drunk, On, Plane, Capitol, R...   ...              70   \n",
       "2  [Thomas, Rhett, Get, Me, Some, Of, That, The, ...   ...              40   \n",
       "3  [David, Nail, Whatever, She's, Got, MCA, Nashv...   ...              60   \n",
       "4      [Joe Nichols, Red Bow Records, Country, Yeah]   ...              30   \n",
       "\n",
       "   colors_8_blue  colors_8_green  colors_9_red  colors_9_blue  colors_9_green  \\\n",
       "0            210             190            90             70              70   \n",
       "1             50              50           100            110             120   \n",
       "2             50              30            50             70              50   \n",
       "3             50              30            60             40              30   \n",
       "4             50              50            20             40              60   \n",
       "\n",
       "   colors_10_red  colors_10_blue  colors_10_green    genre  \n",
       "0            240             220              200  country  \n",
       "1             90              70               70  country  \n",
       "2             40              60               50  country  \n",
       "3             70              60               50  country  \n",
       "4             20              30               50  country  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import sklearn\n",
    "\n",
    "# Edit path if need be (shouldn't need to b/c we all have the same folder structure)\n",
    "CSV_PATH_1 = '../Videos/all_data'\n",
    "CSV_PATH_2 = '../Videos2/all_data2'\n",
    "FILE_EXTENSION = '_all.csv'\n",
    "GENRES = ['country', 'edm', 'pop', 'rap', 'rock']\n",
    "\n",
    "# Containers for the data frames\n",
    "genre_dfs = {}\n",
    "all_genres = None\n",
    "\n",
    "# Read in the 5 genre's of CV's\n",
    "for genre in GENRES:\n",
    "    genre_csv_path_1 = path.join(CSV_PATH_1, genre) + FILE_EXTENSION\n",
    "    genre_csv_path_2 = path.join(CSV_PATH_2, genre) + FILE_EXTENSION\n",
    "    df_1 = pd.read_csv(genre_csv_path_1)\n",
    "    df_2 = pd.read_csv(genre_csv_path_2)\n",
    "    df_1 = df_1.drop('Unnamed: 0',1)\n",
    "    df_2 = df_2.drop('Unnamed: 0',1)\n",
    "    df_combined = pd.concat([df_1,df_2],ignore_index=True)\n",
    "    genre_dfs[genre] = df_combined\n",
    "\n",
    "all_genres = pd.concat(genre_dfs.values())\n",
    "all_genres.head()\n",
    "\n",
    "# genre_dfs is now a dictionary that contains the 5 different data frames\n",
    "# all_genres is a dataframe that contains all of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Genres\n",
    "Below, we make the genres ordinal to fit in the random forest classifiers. We add a new column to our dataframe to do so, write a function to populate it, and run it across the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def genre_to_ordinal(genre_in):\n",
    "    if(genre_in == \"country\"):\n",
    "        return 0\n",
    "    elif(genre_in == \"pop\"):\n",
    "        return 1\n",
    "    elif(genre_in == \"rock\"):\n",
    "        return 2\n",
    "    elif(genre_in == \"edm\"):\n",
    "        return 3\n",
    "    elif(genre_in == \"rap\"):\n",
    "        return 4\n",
    "    else:\n",
    "        return genre_in\n",
    "    \n",
    "all_genres['genre_ordinal'] = all_genres.genre.apply(genre_to_ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add in some boolean genre classifiers to make our analysis more fine-grained. Rather than saying \"we predict this video is country with 50% confidence\", we could say \"we predict this video is not edm with 90% confidence\" and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding is_country flag\n",
    "def is_country(genre_in):\n",
    "    if(genre_in == \"country\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_country'] = all_genres.genre.apply(is_country)\n",
    "\n",
    "# Adding is_country flag\n",
    "def is_rock(genre_in):\n",
    "    if(genre_in == \"rock\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_rock'] = all_genres.genre.apply(is_rock)\n",
    "\n",
    "# Adding is_edm flag\n",
    "def is_edm(genre_in):\n",
    "    if(genre_in == \"edm\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_edm'] = all_genres.genre.apply(is_edm)\n",
    "\n",
    "# Adding is_rap flag\n",
    "def is_rap(genre_in):\n",
    "    if(genre_in == \"rap\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_rap'] = all_genres.genre.apply(is_rap)\n",
    "\n",
    "# Adding is_country flag\n",
    "def is_pop(genre_in):\n",
    "    if(genre_in == \"pop\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "all_genres['is_pop'] = all_genres.genre.apply(is_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Train Sets\n",
    "We create our training and test sets by splitting all_genres by genre, and making 10 of each genre train and 10 test. We aggregate by genre to make our full train and full test sets, each containing 50 records of various genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Records:\t405\n",
      "Test Records:\t\t405\n"
     ]
    }
   ],
   "source": [
    "# Subset all_genres to group by individual genres\n",
    "country_records  = all_genres[all_genres[\"genre\"] == \"country\"]\n",
    "rock_records     = all_genres[all_genres[\"genre\"] == \"rock\"]\n",
    "pop_records      = all_genres[all_genres[\"genre\"] == \"pop\"]\n",
    "edm_records      = all_genres[all_genres[\"genre\"] == \"edm\"]\n",
    "rap_records      = all_genres[all_genres[\"genre\"] == \"rap\"]\n",
    "\n",
    "# From the subsets above, create train and test sets from each\n",
    "country_train = country_records.head(len(country_records) / 2)\n",
    "country_test  = country_records.tail(len(country_records) / 2)\n",
    "rock_train    = rock_records.head(len(rock_records) / 2)\n",
    "rock_test     = rock_records.tail(len(rock_records) / 2)\n",
    "pop_train     = pop_records.head(len(pop_records) / 2)\n",
    "pop_test      = pop_records.tail(len(pop_records) / 2)\n",
    "edm_train     = edm_records.head(len(edm_records) / 2)\n",
    "edm_test      = edm_records.tail(len(edm_records) / 2)\n",
    "rap_train     = rap_records.head(len(rap_records) / 2)\n",
    "rap_test      = rap_records.tail(len(rap_records) / 2)\n",
    "\n",
    "# Create big training and big test set for analysis\n",
    "training_set = pd.concat([country_train,rock_train,pop_train,edm_train,rap_train])\n",
    "test_set     = pd.concat([country_test,rock_test,pop_test,edm_test,rap_test])\n",
    "\n",
    "training_set = training_set.fillna(0)\n",
    "test_set = test_set.fillna(0)\n",
    "\n",
    "print \"Training Records:\\t\" , len(training_set)\n",
    "print \"Test Records:\\t\\t\" , len(test_set)\n",
    "# training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Generating Random Forest - Viewer Statistics\n",
    "We start generating our random forests, and output a relative accuracy and a confusion matrix. In this first one, we simply factor in non-color variables (rating, likes, dislikes, length and viewcount), and run it across all records to predict an ordinal genre value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444444444444\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4\n",
       "Actual                       \n",
       "0          51   5   0  21   4\n",
       "1           2  24  41   7   7\n",
       "2          32   8   3  29   3\n",
       "3           8  14  23  29   9\n",
       "4           7  18   2   7  51"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting based solely on non-color features, using RF\n",
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "meta_data_features = ['rating', 'likes','dislikes','length','viewcount']\n",
    "y, _ = pd.factorize(training_set['genre_ordinal'])\n",
    "clf = clf.fit(training_set[meta_data_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['genre_ordinal'])\n",
    "print clf.score(test_set[meta_data_features],z)\n",
    "pd.crosstab(test_set.genre_ordinal, clf.predict(test_set[meta_data_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, this method yields relatively poor results. This is because there's no distinct clusters being created by our random forest, and simple viewer statistics tell us nothing about what kind of video we're watching. However, we see that country, rap and pop are initially somewhat distinct (diagonal is the highest value), and rock and edm are getting mistaken for one another. Let's see if we can't make something of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Only Color Statistics\n",
    "Below, we do the same random forest as above, but going strictly off of average frame color for the video.\n",
    "\n",
    "We found the most commonly appearing color in each frame and called it the 'frame mode'. We then took all of the frame modes and found the 10 most common of them. Those became the 'color data' we use to analyze videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_new_headers(old_headers):\n",
    "    headers = ['colors_' + str(x+1) + '_' for x in range(10)]\n",
    "    h = []\n",
    "    for x in headers:\n",
    "        h.append(x + 'red')\n",
    "        h.append(x + 'blue')\n",
    "        h.append(x + 'green')\n",
    "    return old_headers + h + ['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.222222222222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4\n",
       "Actual                       \n",
       "0          31  17  16  10   7\n",
       "1          10  15  20  25  11\n",
       "2          38  11   5  13   8\n",
       "3          14  16  30  15   8\n",
       "4          21  19  21  11  13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "color_features = gen_new_headers([])[:-1]\n",
    "\n",
    "# Predicting based solely on colors\n",
    "y, _ = pd.factorize(training_set['genre_ordinal'])\n",
    "clf = clf.fit(training_set[color_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['genre_ordinal'])\n",
    "print clf.score(test_set[color_features],z)\n",
    "pd.crosstab(test_set.genre_ordinal, clf.predict(test_set[color_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually yields worse results than just the viewer statistics, because the color of a video by itself does not determine the genre. If rappers only had red in their videos and rockers only had black this might be somewhat accurate, but that's just not the case. But, what if we pair these findings with our initial viewer statistics? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.372839506173\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4\n",
       "Actual                       \n",
       "0          46   9   2  15   9\n",
       "1           5  24  38   9   5\n",
       "2          21  18   4  23   9\n",
       "3          10  17  25  15  16\n",
       "4          20  17   2  12  34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "all_features = meta_data_features + color_features\n",
    "\n",
    "# Predicting based on colors and non-color features\n",
    "y, _ = pd.factorize(training_set['genre_ordinal'])\n",
    "clf = clf.fit(training_set[all_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['genre_ordinal'])\n",
    "print clf.score(test_set[all_features],z)\n",
    "pd.crosstab(test_set.genre_ordinal, clf.predict(test_set[all_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singling Out Pop and Rap\n",
    "Scores are expectedly low. It seems as if we're trying to make the classifier do way too much work, and are giving it very mediocre data to go off of. Recall that we're actually trying to determine WHICH genre a video is by the above code, not whether or not a video is of ONE specific genre. This brings back the binary classifiers that we created above, let's put those to use to see if we can improve these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We try pop and rap first, since they seem to be the most distinct by what we've gathered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81975308642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1\n",
       "Actual            \n",
       "0          311  13\n",
       "1           60  21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "all_features = meta_data_features + color_features\n",
    "\n",
    "# Predicting based on colors and non-color features\n",
    "y, _ = pd.factorize(training_set['is_pop'])\n",
    "clf = clf.fit(training_set[all_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['is_pop'])\n",
    "print clf.score(test_set[all_features],z)\n",
    "pd.crosstab(test_set.is_pop, clf.predict(test_set[all_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775308641975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>291</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1\n",
       "Actual            \n",
       "0          291  29\n",
       "1           62  23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=11)\n",
    "all_features = meta_data_features + color_features\n",
    "\n",
    "# Predicting based on colors and non-color features\n",
    "y, _ = pd.factorize(training_set['is_rap'])\n",
    "clf = clf.fit(training_set[all_features], y)\n",
    "\n",
    "z, _ = pd.factorize(test_set['is_rap'])\n",
    "print clf.score(test_set[all_features],z)\n",
    "pd.crosstab(test_set.is_rap, clf.predict(test_set[all_features]),rownames=[\"Actual\"], colnames=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're seeing above is a confusion matrix that, based on our training data, predicts whether or not a video in the test set is a pop video or not. In the \"predicted\" row, 0 means it predicts it's not a pop video, and that the 1 is. Likewise with the actual, 0 shows that the video actually wasn't a pop video, and the 1 shows that it was.\n",
    "\n",
    "The confusion matrix above is our first effort at utilizing these binary classifiers. Most of our videos aren't pop videos, and the model did a good job of picking out those that aren't pop. However, we could use some improvement in the realm of \"false negatives\", where the model classified a video as not pop when it actually was."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do these tests 50 times for sake of average score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than hard-coding each time we wanted to run something for average, we wrote a function that does it for us. All we have to do is pass in the boolean classifier in quotes (\"is_rock\", etc.), and the number of iterations that we want. Results are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multi_RF_averages(is_genre,num_iterations):\n",
    "    clf = RandomForestClassifier(n_estimators=11)\n",
    "    loop_indices = range(0,num_iterations)\n",
    "    cumsum = 0\n",
    "\n",
    "    for i in loop_indices:\n",
    "        y, _ = pd.factorize(training_set[is_genre])\n",
    "        clf = clf.fit(training_set[all_features], y)\n",
    "\n",
    "        z, _ = pd.factorize(test_set[is_genre])\n",
    "        cumsum = cumsum + clf.score(test_set[all_features],z)\n",
    "    \n",
    "    \n",
    "    print \"Average Score for\",len(loop_indices),is_genre,\"iterations:\", cumsum/len(loop_indices)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for 50 is_pop iterations: 0.904303797468\n",
      "Average Score for 50 is_rap iterations: 0.889493670886\n",
      "Average Score for 50 is_rock iterations: 0.588607594937\n",
      "Average Score for 50 is_edm iterations: 0.51835443038\n",
      "Average Score for 50 is_country iterations: 0.0744303797468\n"
     ]
    }
   ],
   "source": [
    "pop_class = multi_RF_averages(\"is_pop\",50)\n",
    "rap_class = multi_RF_averages(\"is_rap\",50)\n",
    "rock_class = multi_RF_averages(\"is_rock\",50)\n",
    "edm_class = multi_RF_averages(\"is_edm\",50)\n",
    "country_class = multi_RF_averages(\"is_country\",50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following creates several files that describe our classifiers. Our website will later  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifiers/counry_class.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pop_class, 'classifiers/pop_class.pkl')\n",
    "joblib.dump(rap_class, 'classifiers/rap_class.pkl')\n",
    "joblib.dump(rock_class, 'classifiers/rock_class.pkl')\n",
    "joblib.dump(edm_class, 'classifiers/edm_class.pkl')\n",
    "joblib.dump(country_class, 'classifiers/country_class.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the above test with all genres, and as shown in above analysis, our country and edm typically have very low accuracy. We've seen above that edm and rock videos are getting mixed up with one another, so we assume that something is characteristic of these 2 genres that's not of everything else. We take out the edm values from our training and test datasets, hoping to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for 50 is_pop iterations: 0.841428571429\n",
      "Average Score for 50 is_rap iterations: 0.748819875776\n",
      "Average Score for 50 is_rock iterations: 0.768385093168\n",
      "Average Score for 50 is_edm iterations: 1.0\n",
      "Average Score for 50 is_country iterations: 0.739254658385\n"
     ]
    }
   ],
   "source": [
    "# Removing EDM for better analysis - makes is_pop and is_rap much more accurate\n",
    "training_set = pd.concat([country_train,rock_train,pop_train,rap_train])\n",
    "test_set     = pd.concat([country_test,rock_test,pop_test,rap_test])\n",
    "\n",
    "multi_RF_averages(\"is_pop\",50)\n",
    "multi_RF_averages(\"is_rap\",50)\n",
    "multi_RF_averages(\"is_rock\",50)\n",
    "multi_RF_averages(\"is_edm\",50)\n",
    "multi_RF_averages(\"is_country\",50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So, what does this tell us? Based on our training data, we have the best chance of accurately classifying something as pop or not pop (under these conditions). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find out which 2 are the most distinct, so we can make build our model based on that classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for 50 is_rock iterations: 0.8104\n",
      "Average Score for 50 is_rap iterations: 0.736705882353\n",
      "Average Score for 50 is_country iterations: 0.212345679012\n",
      "Average Score for 50 is_pop iterations: 0.736049382716\n",
      "Average Score for 50 is_edm iterations: 0.920240963855\n"
     ]
    }
   ],
   "source": [
    "training_set = pd.concat([country_train,rock_train,edm_train,rap_train,pop_train])\n",
    "\n",
    "test_set     = pd.concat([rock_test])\n",
    "multi_RF_averages(\"is_rock\",50)\n",
    "\n",
    "test_set     = pd.concat([rap_test])\n",
    "multi_RF_averages(\"is_rap\",50)\n",
    "\n",
    "test_set     = pd.concat([country_test])\n",
    "multi_RF_averages(\"is_country\",50)\n",
    "\n",
    "test_set     = pd.concat([pop_test])\n",
    "multi_RF_averages(\"is_pop\",50)\n",
    "\n",
    "test_set     = pd.concat([edm_test])\n",
    "multi_RF_averages(\"is_edm\",50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rock and EDM have suprisingly distinct classifiers. We should dive into the videos and see what this means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score for 50 is_edm iterations: 0.525696202532\n",
      "Average Score for 50 is_rock iterations: 0.58582278481\n"
     ]
    }
   ],
   "source": [
    "test_set     = pd.concat([edm_test,rock_test])\n",
    "multi_RF_averages(\"is_edm\",50)\n",
    "multi_RF_averages(\"is_rock\",50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Most Valuable Features per Genre - Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03290921  0.03469756  0.03118444  0.04860914  0.01782878  0.01999346\n",
      "  0.03024935  0.04399394  0.02505887  0.03233096  0.02809611  0.02450839\n",
      "  0.03535645  0.02962933  0.01802695  0.02066237  0.03197878  0.02706119\n",
      "  0.02530101  0.0317604   0.0277708   0.03673455  0.03398566  0.02701643\n",
      "  0.02198703  0.02476635  0.02466785  0.02749125  0.04315477  0.0293925\n",
      "  0.01777877  0.02000058  0.02779286  0.02196882  0.02625507]\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "\n",
    "training_set = pd.concat([country_train,pop_train,rap_train,rock_train,edm_train])\n",
    "y, _ = pd.factorize(training_set['is_rock'])\n",
    "model.fit(training_set[all_features], y)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rap</th>\n",
       "      <th>rock</th>\n",
       "      <th>country</th>\n",
       "      <th>edm</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rating</td>\n",
       "      <td>0.037061</td>\n",
       "      <td>0.040522</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>0.040594</td>\n",
       "      <td>0.037252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>likes</td>\n",
       "      <td>0.040754</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.188497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dislikes</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>0.033566</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.145784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>length</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>0.049036</td>\n",
       "      <td>0.024699</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>0.018454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>viewcount</td>\n",
       "      <td>0.058718</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.039757</td>\n",
       "      <td>0.037858</td>\n",
       "      <td>0.108199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>colors_1_red</td>\n",
       "      <td>0.027543</td>\n",
       "      <td>0.032578</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>0.033716</td>\n",
       "      <td>0.015370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>colors_1_blue</td>\n",
       "      <td>0.029278</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.031848</td>\n",
       "      <td>0.027285</td>\n",
       "      <td>0.018871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>colors_1_green</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>0.030655</td>\n",
       "      <td>0.023208</td>\n",
       "      <td>0.028503</td>\n",
       "      <td>0.016904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>colors_2_red</td>\n",
       "      <td>0.030502</td>\n",
       "      <td>0.028434</td>\n",
       "      <td>0.025461</td>\n",
       "      <td>0.023928</td>\n",
       "      <td>0.010516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>colors_2_blue</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>0.029427</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.021818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>colors_2_green</td>\n",
       "      <td>0.020703</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.028675</td>\n",
       "      <td>0.022515</td>\n",
       "      <td>0.014617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>colors_3_red</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.029937</td>\n",
       "      <td>0.018068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>colors_3_blue</td>\n",
       "      <td>0.019552</td>\n",
       "      <td>0.032209</td>\n",
       "      <td>0.022710</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.019743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>colors_3_green</td>\n",
       "      <td>0.018391</td>\n",
       "      <td>0.028266</td>\n",
       "      <td>0.029460</td>\n",
       "      <td>0.019374</td>\n",
       "      <td>0.014468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>colors_4_red</td>\n",
       "      <td>0.016173</td>\n",
       "      <td>0.025636</td>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.016155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>colors_4_blue</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.032348</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.016265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>colors_4_green</td>\n",
       "      <td>0.026606</td>\n",
       "      <td>0.037959</td>\n",
       "      <td>0.042957</td>\n",
       "      <td>0.020225</td>\n",
       "      <td>0.013988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colors_5_red</td>\n",
       "      <td>0.021346</td>\n",
       "      <td>0.025909</td>\n",
       "      <td>0.030420</td>\n",
       "      <td>0.027754</td>\n",
       "      <td>0.012087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>colors_5_blue</td>\n",
       "      <td>0.028953</td>\n",
       "      <td>0.021586</td>\n",
       "      <td>0.026070</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.016589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>colors_5_green</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>0.033031</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.032165</td>\n",
       "      <td>0.015722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>colors_6_red</td>\n",
       "      <td>0.024367</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.020074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>colors_6_blue</td>\n",
       "      <td>0.029226</td>\n",
       "      <td>0.027554</td>\n",
       "      <td>0.028215</td>\n",
       "      <td>0.032130</td>\n",
       "      <td>0.017413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>colors_6_green</td>\n",
       "      <td>0.026308</td>\n",
       "      <td>0.025758</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.035228</td>\n",
       "      <td>0.017020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>colors_7_red</td>\n",
       "      <td>0.029457</td>\n",
       "      <td>0.024127</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.034723</td>\n",
       "      <td>0.017566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>colors_7_blue</td>\n",
       "      <td>0.027420</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.021780</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>0.013155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>colors_7_green</td>\n",
       "      <td>0.031601</td>\n",
       "      <td>0.017611</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.033237</td>\n",
       "      <td>0.019533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>colors_8_red</td>\n",
       "      <td>0.036723</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.023019</td>\n",
       "      <td>0.033311</td>\n",
       "      <td>0.020048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>colors_8_blue</td>\n",
       "      <td>0.027478</td>\n",
       "      <td>0.023290</td>\n",
       "      <td>0.033166</td>\n",
       "      <td>0.039334</td>\n",
       "      <td>0.015507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>colors_8_green</td>\n",
       "      <td>0.026149</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>0.027504</td>\n",
       "      <td>0.031502</td>\n",
       "      <td>0.017796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>colors_9_red</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>0.029016</td>\n",
       "      <td>0.030778</td>\n",
       "      <td>0.029691</td>\n",
       "      <td>0.016235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>colors_9_blue</td>\n",
       "      <td>0.026805</td>\n",
       "      <td>0.028311</td>\n",
       "      <td>0.028116</td>\n",
       "      <td>0.025264</td>\n",
       "      <td>0.012713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>colors_9_green</td>\n",
       "      <td>0.034946</td>\n",
       "      <td>0.022946</td>\n",
       "      <td>0.025116</td>\n",
       "      <td>0.019536</td>\n",
       "      <td>0.011670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>colors_10_red</td>\n",
       "      <td>0.033544</td>\n",
       "      <td>0.031377</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>0.034841</td>\n",
       "      <td>0.023482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>colors_10_blue</td>\n",
       "      <td>0.028774</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>0.022062</td>\n",
       "      <td>0.016430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>colors_10_green</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0.020136</td>\n",
       "      <td>0.028255</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>0.021993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index       rap      rock   country       edm       pop\n",
       "0            rating  0.037061  0.040522  0.034231  0.040594  0.037252\n",
       "1             likes  0.040754  0.034703  0.049799  0.017125  0.188497\n",
       "2          dislikes  0.034943  0.033566  0.034409  0.023285  0.145784\n",
       "3            length  0.041574  0.049036  0.024699  0.022436  0.018454\n",
       "4         viewcount  0.058718  0.028356  0.039757  0.037858  0.108199\n",
       "5      colors_1_red  0.027543  0.032578  0.023257  0.033716  0.015370\n",
       "6     colors_1_blue  0.029278  0.030500  0.031848  0.027285  0.018871\n",
       "7    colors_1_green  0.023380  0.030655  0.023208  0.028503  0.016904\n",
       "8      colors_2_red  0.030502  0.028434  0.025461  0.023928  0.010516\n",
       "9     colors_2_blue  0.023691  0.025346  0.029427  0.027073  0.021818\n",
       "10   colors_2_green  0.020703  0.035088  0.028675  0.022515  0.014617\n",
       "11     colors_3_red  0.016700  0.031536  0.024167  0.029937  0.018068\n",
       "12    colors_3_blue  0.019552  0.032209  0.022710  0.016018  0.019743\n",
       "13   colors_3_green  0.018391  0.028266  0.029460  0.019374  0.014468\n",
       "14     colors_4_red  0.016173  0.025636  0.027028  0.031710  0.016155\n",
       "15    colors_4_blue  0.032124  0.027042  0.032348  0.027174  0.016265\n",
       "16   colors_4_green  0.026606  0.037959  0.042957  0.020225  0.013988\n",
       "17     colors_5_red  0.021346  0.025909  0.030420  0.027754  0.012087\n",
       "18    colors_5_blue  0.028953  0.021586  0.026070  0.029740  0.016589\n",
       "19   colors_5_green  0.020776  0.033031  0.018920  0.032165  0.015722\n",
       "20     colors_6_red  0.024367  0.022696  0.026700  0.026700  0.020074\n",
       "21    colors_6_blue  0.029226  0.027554  0.028215  0.032130  0.017413\n",
       "22   colors_6_green  0.026308  0.025758  0.021905  0.035228  0.017020\n",
       "23     colors_7_red  0.029457  0.024127  0.027120  0.034723  0.017566\n",
       "24    colors_7_blue  0.027420  0.024328  0.021780  0.026329  0.013155\n",
       "25   colors_7_green  0.031601  0.017611  0.033784  0.033237  0.019533\n",
       "26     colors_8_red  0.036723  0.030345  0.023019  0.033311  0.020048\n",
       "27    colors_8_blue  0.027478  0.023290  0.033166  0.039334  0.015507\n",
       "28   colors_8_green  0.026149  0.021679  0.027504  0.031502  0.017796\n",
       "29     colors_9_red  0.029045  0.029016  0.030778  0.029691  0.016235\n",
       "30    colors_9_blue  0.026805  0.028311  0.028116  0.025264  0.012713\n",
       "31   colors_9_green  0.034946  0.022946  0.025116  0.019536  0.011670\n",
       "32    colors_10_red  0.033544  0.031377  0.016868  0.034841  0.023482\n",
       "33   colors_10_blue  0.028774  0.018868  0.028822  0.022062  0.016430\n",
       "34  colors_10_green  0.019392  0.020136  0.028255  0.037696  0.021993"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['index'] = all_features\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_rap'])\n",
    "model.fit(training_set[all_features], y)\n",
    "        \n",
    "df['rap'] = model.feature_importances_\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_rock'])\n",
    "model.fit(training_set[all_features], y)\n",
    "\n",
    "df['rock'] = model.feature_importances_\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_country'])\n",
    "model.fit(training_set[all_features], y)\n",
    "\n",
    "df['country'] = model.feature_importances_\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_edm'])\n",
    "model.fit(training_set[all_features], y)\n",
    "\n",
    "df['edm'] = model.feature_importances_\n",
    "\n",
    "y, _ = pd.factorize(training_set['is_pop'])\n",
    "model.fit(training_set[all_features], y)\n",
    "\n",
    "df['pop'] = model.feature_importances_\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Improvements \n",
    "- Run the above graph a number of times, take the average for each cell\n",
    "- Based on the heaviest weighted parameters for each, run the random forest algorithm only taking these given parameters into consideration\n",
    "- Generate a model that classifies videos dynamically\n",
    "- Make more values ordinal - maybe to NLP or LDA to factor in descriptions, titles and lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs489]",
   "language": "python",
   "name": "conda-env-cs489-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
